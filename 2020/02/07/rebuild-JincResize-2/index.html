<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> JincResize 代码重构（2） · 308实验室</title><meta name="description" content="JincResize 代码重构（2） - Kiyamou"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://yoursite.com/atom.xml" title="308实验室"><meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="308实验室" type="application/atom+xml">
</head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/circle.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/Kiyamou" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/about" target="_self" class="nav-list-link">ABOUT</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">JincResize 代码重构（2）</h1><div class="post-info">Feb 7, 2020</div><div class="post-content"><h3 id="指令集优化"><a href="#指令集优化" class="headerlink" title="指令集优化"></a>指令集优化</h3><h4 id="Generation"><a href="#Generation" class="headerlink" title="Generation"></a>Generation</h4><p>（更多内容可查看<a href="http://enigmahuang.me/2017/09/29/AVX-SIMD/" target="_blank" rel="noopener">使用 AVX 系列指令集进行向量化</a>，也可看一下这篇很欢乐的文章<a href="https://zhuanlan.zhihu.com/p/59868499" target="_blank" rel="noopener">GCC神坑：-march=native</a>）</p>
<p>对于GCC编译器，在编译命令中加入<code>-march=native</code>选项，可调用本地的库，使用AVX指令集优化。</p>
<h4 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h4><p>（Doc在<a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm_malloc" target="_blank" rel="noopener">这里</a>，直接搜索想查的函数即可）</p>
<p>（另外也可看一下<a href="http://kawa0810.hateblo.jp/entry/20120304/1330852197" target="_blank" rel="noopener">Intel AVX を使用して SIMD 演算を試してみる - その2 -</a>，但函数参数不如上面的Doc详细）</p>
<p><code>_mm_malloc(size_t size, size_t align)</code>：对齐的问题</p>
<p><code>_mm256_load_ps</code>：float类型输入</p>
<p><code>_mm256_load_pd</code>：double类型输入</p>
<p><code>__m256d _mm256_mul_pd(__m256d, __m256d)</code>：256位双精度乘法</p>
<a id="more"></a>

<h4 id="Type"><a href="#Type" class="headerlink" title="Type"></a>Type</h4><p>（来自<a href="https://www.xlsoft.com/jp/products/intel/compilers/manual/14/cpp/GUID-A9C3B12F-7A9A-4C8D-A6CD-9974ABC570E9.htm" target="_blank" rel="noopener">インテル® アドバンスト・ベクトル・エクステンション (インテル® AVX) 組込み関数の詳細</a>）</p>
<p><code>__m256</code>：容纳8个32位单精度浮点数值</p>
<p><code>__m256d</code>：容纳4个64位双精度浮点数值</p>
<h4 id="实际代码"><a href="#实际代码" class="headerlink" title="实际代码"></a>实际代码</h4><p>这部分代码来自luglio，我只是做了一点适配，因为我现在还没有把JincResize的中间数据从double改为float。</p>
<h5 id="对齐的问题"><a href="#对齐的问题" class="headerlink" title="对齐的问题"></a>对齐的问题</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">double</span>* lut = (<span class="keyword">double</span> *)_mm_malloc(<span class="keyword">sizeof</span>(<span class="keyword">double</span>) * d-&gt;sample, <span class="number">64</span>);</span><br></pre></td></tr></table></figure>

<p><code>_mm_malloc</code>相比一般的<code>malloc</code>，增加了一个用于数据对齐的参数。具体在这里（<a href="https://software.intel.com/zh-cn/articles/data-alignment-to-assist-vectorization" target="_blank" rel="noopener">数据对齐有助于实现向量化</a>）有讲。</p>
<p>虽然我现在还不能完全理解这个概念，但经过测试，对于JincResize现有的代码，把上面的<code>64</code>写成<code>32</code>，和没有AVX优化的速度几乎一样。</p>
<h5 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">__mm256_store_ps(lut + j * <span class="number">8</span>, rl);  <span class="comment">// float</span></span><br><span class="line">__mm256_store_pd(lut + j * <span class="number">4</span>, rl);  <span class="comment">// double</span></span><br></pre></td></tr></table></figure>

<p>看一下两个函数的声明</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> _mm256_store_ps (<span class="keyword">float</span> * mem_addr, __m256 a)</span><br><span class="line"><span class="keyword">void</span> _mm256_store_pd (<span class="keyword">double</span> * mem_addr, __m256d a)</span><br></pre></td></tr></table></figure>

<p>注意到第二个参数类型分别是<code>__m256</code>、<code>__m256d</code>，所以有了上述区别。</p>
<h3 id="代码细节的整理"><a href="#代码细节的整理" class="headerlink" title="代码细节的整理"></a>代码细节的整理</h3><p>（2020.3.2完成 2020.3.8补记）</p>
<h4 id="删去冗余代码"><a href="#删去冗余代码" class="headerlink" title="删去冗余代码"></a>删去冗余代码</h4><p>之前没注意，可以直接获取特定平面尺寸的啊（commit <a href="https://github.com/Kiyamou/VapourSynth-JincResize/commit/83eb7fb83a887d1237607621926c40d68aff7830" target="_blank" rel="noopener">83eb7f</a>）。</p>
<h4 id="把乘方换成乘法"><a href="#把乘方换成乘法" class="headerlink" title="把乘方换成乘法"></a>把乘方换成乘法</h4><p>嗯，就是求平方嘛，直接乘多好，用<code>pow()</code>更慢。</p>
<p>说起来虽然是这么一个小改动，但速度提升真是明显（从r5到r6的25%速度提升，AVX优化贡献的可能还不如这里多）。毕竟是在计算量最大的四重循环内，微小的改动就能有大的影响。</p>
<p>经过从r5到r6的修改，以及对卷积的认识，算是把JincResize代码重新认识了一遍，哪里是速度敏感的，怎么样让代码简洁一点，也有了体会。</p>
</div></article></div></main><footer><div class="paginator"><a href="/2020/02/08/ISP-learn-1/" class="prev">PREV</a><a href="/2020/02/07/arch-and-meson/" class="next">NEXT</a></div><div class="copyright"><p>© 2019 - 2020 <a href="http://yoursite.com">Kiyamou</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>